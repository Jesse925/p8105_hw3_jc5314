---
title: "P8105 Homework 3"
author: "Junxian Chen (jc5314)"
date: "10/6/2019"
output: github_document
---


# Problem 1

Load the libraries and data:

```{r, message = FALSE}
library(tidyverse)
library(p8105.datasets)
data("instacart")
```

### 1. Description of the dataset:

* **Size of the dataset**: The dataset contains `r nrow(instacart)` observations and `r ncol(instacart)` variables.

* **Structure of the data**: The dataset records information of online grocery orders from the Instacart users. Each row represents one order of a product. Variables showing order information, product information, customer information, aisle information, information of purchasing time, etc., are included in the dataset.

* **Key variables**: 

(1) The mean of the values in variable `reordered` is `r mean(pull(instacart, reordered))`, which means that nearly 60% products were reordered. 

(2) In variable `order_dow` which menas the day of week the order was placed, the value '`r names(sort(table(pull(instacart, order_dow)),decreasing=TRUE))[1]`' appeares the most. This means that most products were ordered on Sunday. 

(3) In variable `order_hour_of_day` which menas the hour of day the order was placed, the value '`r names(sort(table(pull(instacart, order_hour_of_day)),decreasing=TRUE))[1]`' appeares the most. This means that most products were ordered at 2 pm. 

(4) In variable `days_since_prior_order`, the mean value is `r mean(pull(instacart, days_since_prior_order))`, which means that people would order again after 17 days on average. 

(5) For variable `aisle`, there are `r length(unique(pull(instacart, aisle)))` aisles in total, and the aisles that the most items ordered from is '`r names(sort(table(pull(instacart, aisle)),decreasing=TRUE))[1]`'.

* **Illstrative example of observations**:

Below is the first row of observations in the dataset. It represents an order of a product from one customer. In this example, the data tell us a customer brought a Bulgarian Yogurt from the 'yogurt' aisle at 10 am on Thursday. This was a re-order from this customer and it has been 9 days since his/her last order.

`r instacart[1,] %>% knitr::kable()`

### 2. Answers to the questions:

* There are `r length(unique(pull(instacart, aisle)))` aisles in total, and the aisles that the most items ordered from is '`r names(sort(table(pull(instacart, aisle)),decreasing=TRUE))[1]`'. *Comment*: It shows that those customers had large demands in fresh vegetables and they may had health lifestyles.

* A plot that shows the number of items ordered in each aisle, limiting to aisles with more than 10000 items orderedï¼š

```{r, fig.width = 8}
aisle_plot = 
  instacart %>% 
  count(aisle, name = 'number_of_items_ordered') %>%
  filter(number_of_items_ordered > 10000) %>%
  ggplot(aes(reorder(aisle, number_of_items_ordered), x = number_of_items_ordered)) + 
    geom_point() +
    xlab('Number of each item ordered') +
    ylab('Aisle name') +
    labs(title = 'Number of items ordered in each aisle with more than 10000 items ordered')
  
# show the plot

aisle_plot
```

*Comment*: The aisles that sell fresh vegetables, fresh fruits, and packaged vegetables fruits had the top three number of itmes ordered. Most of the remained aisles had less than 40,000 items orderd.

* A table showing the three most popular items in each of the aisles `baking ingredients`, `dog food care`, and `packaged vegetables fruits` (numbers of times each item is ordered are also included):

```{r}
pop_item = 
  instacart %>% 
  filter(
    aisle %in% c('baking ingredients', 'dog food care', 'packaged vegetables fruits')
  ) %>% 
  group_by(aisle) %>% 
  count(product_name, name = 'number_of_ordered_time') %>% 
  top_n(n = 3, wt = number_of_ordered_time) %>% 
  knitr::kable(col.names = c('Aisle name', 'Top 3 popular items on this aisle', 'Number of ordered time'),
               caption = 'Table 1: The 3 most popular items in the given aisles and their numbers of time being ordered.')

# show the table

pop_item
```

*Comment*: The top three most ordered ingredients for baking were cane sugar, light brown sugar, and pure baking soda. People love buying organic food, even for their dog. 

* A table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:

```{r}
table_p1 = 
  instacart %>% 
    filter(
    product_name %in% c('Pink Lady Apples', 'Coffee Ice Cream')
  ) %>% 
  group_by(product_name, order_dow) %>% 
  mutate(mean_hour = mean(order_hour_of_day)) %>% 
  select(product_name, order_dow, mean_hour) %>% 
  arrange(order_dow) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour,
    values_fn = list(mean_hour = mean)
  ) %>% 
  knitr::kable(col.names = c('Product Name', 'Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'),
               caption = 'Table 2: Mean hour of the day at which the product was ordered on each day of the week.') 

# show the table

table_p1
```

*Comment*: Both of the Pink Lady Apples and Coffee Ice Cream were ordered in the noon around 11 a.m. ~ 3 p.m. on average on each day of week.

# Problem 2

Load the data:

```{r}
data("brfss_smart2010")
```

### 1. Clean the data:

```{r}
brfss_dat = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, location = locationdesc) %>% 
  filter(
    topic == 'Overall Health',
    response %in% c('Poor', 'Fair', 'Good', 'Very good', 'Excellent')) %>% 
  mutate(
    response = factor(response, levels = c('Poor', 'Fair', 'Good', 'Very good', 'Excellent'))
  )
  
```

### 2. Answers to the questions:

For 2002:

```{r}
brfss_dat %>% 
  filter(year == '2002') %>% 
  group_by(state, location) %>% 
  summarize() %>% 
  summarize(number_of_location_observed = n()) %>% 
  filter(number_of_location_observed >= 7)
```

* Based on the above results, in 2002 the states that were observed at 7 or more locations were: CT, FL, MA, NC, NJ, and PA.

For 2010:

```{r}
brfss_dat %>% 
  filter(year == '2010') %>% 
  group_by(state, location) %>% 
  summarize() %>% 
  summarize(number_of_location_observed = n()) %>% 
  filter(number_of_location_observed >= 7)
```

* Based on the above esults, in 2010 the states that were observed at 7 or more locations were: CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, and WA.

*Comment*: Much more locations in different states in US were included in the observation in 2010 than in 2002, and Florida had the most observed locations (up to 41) in 2010.

```{r}
excellent_dat =   
  brfss_dat %>% 
  filter(response == 'Excellent') %>% 
  group_by(year, state) %>% 
  mutate(data_value_mean = mean(data_value, na.rm = TRUE)) %>% 
  select(year, state, data_value_mean) %>% 
  distinct()
```

```{r, fig.width = 9}
spaghetti_plot = 
  excellent_dat %>% 
  ggplot(aes(x = year, y = data_value_mean, color = state)) +
  geom_line() +
  xlab('Year') + 
  ylab('Mean data value')

# show the plot

spaghetti_plot
```

*Comment:* The vaerage values of recorded data of those states were quite fluctuant during 2002 to 2010, and the overall trend was decreasing. 

```{r}
data_value_plot = 
  brfss_dat %>% 
  filter(
    year %in% c(2006, 2010),
    state == 'NY') %>% 
  ggplot(aes(x = response, y = data_value)) +
  geom_point() +
  xlab('Response') +
  ylab('Data value') +
  facet_grid(~year)

# show the plot
  
data_value_plot
```

*Comment:* The distribution of points in the plot of 2006 is similar to that in 2010: the 'Good' and 'Very good' responses had relatively higher data values and the 'poor' response had relatively lower data values. 

# Problem 3

### 1. Load and tidy the dataset:

```{r, message = FALSE, overlap = TRUE}
acc_dat = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday') ~ 'Weekday',
      day %in% c('Saturday', 'Sunday') ~ 'Weekend',
    ),
    day = factor(day, levels = c('Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday')),
    week = as.integer(week),
    day_id = as.integer(day_id)
  ) %>% 
  pivot_longer(
    activity_1:activity_1440, 
    names_to = "act_id", 
    values_to = "act_value"
  )

str(acc_dat)
```

Description of the dataset:

After tidying and wrangling the raw data, the resulting dataset now contains `r ncol(acc_dat)` variables: `week` is the the week number, `day_id` is the ID represents the order in which the days appear in the datase, `day` represnts the day of week, `weekday_weekend` indicates whether this day is a weekday or weekend, `act_id` is the ID for each activity record in each minute, `act_value` is the value of the activity recorded in each minute. There are total `r nrow(acc_dat)` observations in this dataset which equals to 1440 mins x 5 weeks x 7 days.

```{r}
total_day_activity =
  acc_dat  %>% 
  group_by(week, day) %>% 
  summarize(sum_act = sum(act_value)) %>%
  knitr::kable(
    col.names = c('Week', 'Day of week', 'Total value of daily activity')
  )

# show the table

total_day_activity
```

*Comment:*

```{r,   fig.width = 10, fig.asp = 0.5}
activity_plot = 
 acc_dat %>%
 group_by(week) %>% 
 arrange(week, day) %>% 
  ungroup() %>% 
 mutate(
   id = seq.int(nrow(acc_dat))
 ) %>% 
  ggplot(aes(x = id, y = act_value, group = week)) + 
  #geom_point(alpha = .5, size = .5) + 
  geom_line(aes(color = day)) +
  scale_x_continuous(
    breaks = seq(0, 50400, by = 1440),
    labels = c('Day 0', 'Day 1', 'Day 2', 'Day 3', 'Day 4', 'Day 5', 'Day 6', 'Day 7', 'Day 8', 'Day 9', 'Day 10', 'Day 11', 'Day 12', 'Day 13', 'Day 14', 'Day 15', 'Day 16', 'Day 17', 
               'Day 18', 'Day 19', 'Day 20', 'Day 21', 'Day 22', 'Day 23', 'Day 24', 'Day 25', 'Day 26', 'Day 27', 'Day 28', 'Day 29', 'Day 30', 'Day 31', 'Day 32', 'Day 33', 'Day 34', 'Day 35')
  ) +
  xlab('Day') +
  ylab('Activity value') +
  scale_color_hue(name = "Day of week") +
  theme(legend.position = "bottom")

activity_plot
```

